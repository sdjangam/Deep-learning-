{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify movie reviews: binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The IMDB dataset comes packaged with TensorFlow.\n",
    "#It has already been preprocessed such that the reviews (sequences of words) have been \n",
    "#converted to sequences of integers, where each integer represents a specific word in a dictionary.\n",
    "\n",
    "#The following code downloads the IMDB dataset to your machine (or uses a cached copy if you've already downloaded it)\n",
    "\n",
    "#keras location is ~/.keras or c:\\users\\<username>\\.keras\n",
    "\n",
    "imdb = keras.datasets.imdb\n",
    "import os\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000, path=os.getcwd()+\"/imdb.npz\")\n",
    "#The argument num_words=10000 keeps the top 10,000 most frequently occurring words in the training data. \n",
    "#The rare words are discarded to keep the size of the data manageable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training entries: 25000, labels: 25000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training entries: {}, labels: {}\".format(len(train_data), len(train_labels)))\n",
    "train_labels[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(218, 189)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data[0])\n",
    "len(train_data[0]), len(train_data[1])\n",
    "#Each label is an integer value of either 0 or 1, where 0 is a negative review, and 1 is a positive review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the integers back to words\n",
    "# A dictionary mapping words to an integer index\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "# The first indices are reserved\n",
    "word_index = {k:(v+3) for k,v in word_index.items()} \n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  # unknown\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_review(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the data\n",
    "#One-hot-encode the arrays to convert them into vectors of 0s and 1s.\n",
    "#For example, the sequence [3, 5] would become a 10,000-D vector that is\n",
    "#all zeros except for indices 3 and 5, which are ones. Then, make this the\n",
    "#first layer in our network—a Dense layer—that can handle floating point \n",
    "#vector data. This approach is memory intensive, though, requiring a \n",
    "#num_words * num_reviews size matrix.\n",
    "\n",
    "#Alternatively, we can pad the arrays so they all have the same length,\n",
    "#then create an integer tensor of shape num_examples * max_length. We can\n",
    "#use an embedding layer capable of handling this shape as the first layer in our network.\n",
    "\n",
    "#we will use the second approach.\n",
    "\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
    "value=word_index[\"<PAD>\"],padding='post',maxlen=256)\n",
    "\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
    "value=word_index[\"<PAD>\"],padding='post',maxlen=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1   14   22   16   43  530  973 1622 1385   65  458 4468   66 3941\n",
      "    4  173   36  256    5   25  100   43  838  112   50  670    2    9\n",
      "   35  480  284    5  150    4  172  112  167    2  336  385   39    4\n",
      "  172 4536 1111   17  546   38   13  447    4  192   50   16    6  147\n",
      " 2025   19   14   22    4 1920 4613  469    4   22   71   87   12   16\n",
      "   43  530   38   76   15   13 1247    4   22   17  515   17   12   16\n",
      "  626   18    2    5   62  386   12    8  316    8  106    5    4 2223\n",
      " 5244   16  480   66 3785   33    4  130   12   16   38  619    5   25\n",
      "  124   51   36  135   48   25 1415   33    6   22   12  215   28   77\n",
      "   52    5   14  407   16   82    2    8    4  107  117 5952   15  256\n",
      "    4    2    7 3766    5  723   36   71   43  530  476   26  400  317\n",
      "   46    7    4    2 1029   13  104   88    4  381   15  297   98   32\n",
      " 2071   56   26  141    6  194 7486   18    4  226   22   21  134  476\n",
      "   26  480    5  144   30 5535   18   51   36   28  224   92   25  104\n",
      "    4  226   65   16   38 1334   88   12   16  283    5   16 4472  113\n",
      "  103   32   15   16 5345   19  178   32    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "len(train_data[0]), len(train_data[1])\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,289\n",
      "Trainable params: 160,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Build the model\n",
    "# input shape is the vocabulary count used for the movie reviews (10,000 words)\n",
    "vocab_size = 10000\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The layers are stacked sequentially to build the classifier:\n",
    "\n",
    "- The first layer is an Embedding layer. This layer takes the integer-encoded vocabulary and looks up the embedding vector for each word-index. These vectors are learned as the model trains. The vectors add a dimension to the output array. The resulting dimensions are: (batch, sequence, embedding).\n",
    "- Next, a GlobalAveragePooling1D layer returns a fixed-length output vector for each example by averaging over the sequence dimension. This allows the model can handle input of variable length, in the simplest way possible.\n",
    "- This fixed-length output vector is piped through a fully-connected (Dense) layer with 16 hidden units.\n",
    "- The last layer is densely connected with a single output node. Using the sigmoid activation function, this value is a float between 0 and 1, representing a probability, or confidence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(), loss='binary_crossentropy',metrics=['accuracy'])\n",
    "x_val = train_data[:10000]\n",
    "partial_x_train = train_data[10000:]\n",
    "\n",
    "y_val = train_labels[:10000]\n",
    "partial_y_train = train_labels[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "15000/15000 [==============================] - 1s 83us/step - loss: 0.6911 - acc: 0.6419 - val_loss: 0.6883 - val_acc: 0.7121\n",
      "Epoch 2/40\n",
      "15000/15000 [==============================] - 1s 52us/step - loss: 0.6828 - acc: 0.7443 - val_loss: 0.6768 - val_acc: 0.7153\n",
      "Epoch 3/40\n",
      "15000/15000 [==============================] - 1s 54us/step - loss: 0.6654 - acc: 0.7610 - val_loss: 0.6550 - val_acc: 0.7463\n",
      "Epoch 4/40\n",
      "15000/15000 [==============================] - 1s 59us/step - loss: 0.6357 - acc: 0.7661 - val_loss: 0.6227 - val_acc: 0.7805\n",
      "Epoch 5/40\n",
      "15000/15000 [==============================] - 1s 48us/step - loss: 0.5948 - acc: 0.8036 - val_loss: 0.5807 - val_acc: 0.7948\n",
      "Epoch 6/40\n",
      "15000/15000 [==============================] - 1s 50us/step - loss: 0.5467 - acc: 0.8247 - val_loss: 0.5359 - val_acc: 0.8087\n",
      "Epoch 7/40\n",
      "15000/15000 [==============================] - 1s 49us/step - loss: 0.4965 - acc: 0.8443 - val_loss: 0.4914 - val_acc: 0.8283\n",
      "Epoch 8/40\n",
      "15000/15000 [==============================] - 1s 49us/step - loss: 0.4490 - acc: 0.8612 - val_loss: 0.4514 - val_acc: 0.8443\n",
      "Epoch 9/40\n",
      "15000/15000 [==============================] - 1s 53us/step - loss: 0.4073 - acc: 0.8699 - val_loss: 0.4177 - val_acc: 0.8531\n",
      "Epoch 10/40\n",
      "15000/15000 [==============================] - 1s 48us/step - loss: 0.3711 - acc: 0.8816 - val_loss: 0.3904 - val_acc: 0.8593\n",
      "Epoch 11/40\n",
      "15000/15000 [==============================] - 1s 49us/step - loss: 0.3412 - acc: 0.8895 - val_loss: 0.3704 - val_acc: 0.8624\n",
      "Epoch 12/40\n",
      "15000/15000 [==============================] - 1s 57us/step - loss: 0.3166 - acc: 0.8965 - val_loss: 0.3507 - val_acc: 0.8705\n",
      "Epoch 13/40\n",
      "15000/15000 [==============================] - 1s 45us/step - loss: 0.2938 - acc: 0.9022 - val_loss: 0.3370 - val_acc: 0.8734\n",
      "Epoch 14/40\n",
      "15000/15000 [==============================] - 1s 49us/step - loss: 0.2748 - acc: 0.9084 - val_loss: 0.3252 - val_acc: 0.8744\n",
      "Epoch 15/40\n",
      "15000/15000 [==============================] - 1s 51us/step - loss: 0.2583 - acc: 0.9129 - val_loss: 0.3160 - val_acc: 0.8772\n",
      "Epoch 16/40\n",
      "15000/15000 [==============================] - 1s 48us/step - loss: 0.2441 - acc: 0.9169 - val_loss: 0.3084 - val_acc: 0.8786\n",
      "Epoch 17/40\n",
      "15000/15000 [==============================] - 1s 51us/step - loss: 0.2303 - acc: 0.9219 - val_loss: 0.3021 - val_acc: 0.8810\n",
      "Epoch 18/40\n",
      "15000/15000 [==============================] - 1s 44us/step - loss: 0.2183 - acc: 0.9257 - val_loss: 0.2971 - val_acc: 0.8819\n",
      "Epoch 19/40\n",
      "15000/15000 [==============================] - 1s 49us/step - loss: 0.2071 - acc: 0.9297 - val_loss: 0.2936 - val_acc: 0.8826\n",
      "Epoch 20/40\n",
      "15000/15000 [==============================] - 1s 51us/step - loss: 0.1972 - acc: 0.9337 - val_loss: 0.2900 - val_acc: 0.8824\n",
      "Epoch 21/40\n",
      "15000/15000 [==============================] - 1s 49us/step - loss: 0.1877 - acc: 0.9383 - val_loss: 0.2876 - val_acc: 0.8835\n",
      "Epoch 22/40\n",
      "15000/15000 [==============================] - 1s 49us/step - loss: 0.1789 - acc: 0.9417 - val_loss: 0.2862 - val_acc: 0.8846\n",
      "Epoch 23/40\n",
      "15000/15000 [==============================] - 1s 50us/step - loss: 0.1710 - acc: 0.9461 - val_loss: 0.2854 - val_acc: 0.8835\n",
      "Epoch 24/40\n",
      "15000/15000 [==============================] - 1s 50us/step - loss: 0.1630 - acc: 0.9491 - val_loss: 0.2842 - val_acc: 0.8856\n",
      "Epoch 25/40\n",
      "15000/15000 [==============================] - 1s 46us/step - loss: 0.1561 - acc: 0.9521 - val_loss: 0.2841 - val_acc: 0.8854\n",
      "Epoch 26/40\n",
      "15000/15000 [==============================] - 1s 52us/step - loss: 0.1491 - acc: 0.9544 - val_loss: 0.2844 - val_acc: 0.8858\n",
      "Epoch 27/40\n",
      "15000/15000 [==============================] - 1s 50us/step - loss: 0.1432 - acc: 0.9567 - val_loss: 0.2859 - val_acc: 0.8839\n",
      "Epoch 28/40\n",
      "15000/15000 [==============================] - 1s 50us/step - loss: 0.1372 - acc: 0.9597 - val_loss: 0.2857 - val_acc: 0.8859\n",
      "Epoch 29/40\n",
      "15000/15000 [==============================] - 1s 55us/step - loss: 0.1316 - acc: 0.9611 - val_loss: 0.2870 - val_acc: 0.8868\n",
      "Epoch 30/40\n",
      "15000/15000 [==============================] - 1s 50us/step - loss: 0.1268 - acc: 0.9635 - val_loss: 0.2890 - val_acc: 0.8868\n",
      "Epoch 31/40\n",
      "15000/15000 [==============================] - 1s 48us/step - loss: 0.1209 - acc: 0.9658 - val_loss: 0.2907 - val_acc: 0.8864\n",
      "Epoch 32/40\n",
      "15000/15000 [==============================] - 1s 47us/step - loss: 0.1164 - acc: 0.9677 - val_loss: 0.2931 - val_acc: 0.8854\n",
      "Epoch 33/40\n",
      "15000/15000 [==============================] - 1s 49us/step - loss: 0.1113 - acc: 0.9696 - val_loss: 0.2953 - val_acc: 0.8848\n",
      "Epoch 34/40\n",
      "15000/15000 [==============================] - 1s 52us/step - loss: 0.1071 - acc: 0.9711 - val_loss: 0.2991 - val_acc: 0.8841\n",
      "Epoch 35/40\n",
      "15000/15000 [==============================] - 1s 46us/step - loss: 0.1034 - acc: 0.9722 - val_loss: 0.3008 - val_acc: 0.8853\n",
      "Epoch 36/40\n",
      "15000/15000 [==============================] - 1s 45us/step - loss: 0.0988 - acc: 0.9750 - val_loss: 0.3039 - val_acc: 0.8837\n",
      "Epoch 37/40\n",
      "15000/15000 [==============================] - 1s 51us/step - loss: 0.0951 - acc: 0.9761 - val_loss: 0.3070 - val_acc: 0.8838\n",
      "Epoch 38/40\n",
      "15000/15000 [==============================] - 1s 50us/step - loss: 0.0919 - acc: 0.9767 - val_loss: 0.3118 - val_acc: 0.8817\n",
      "Epoch 39/40\n",
      "15000/15000 [==============================] - 1s 47us/step - loss: 0.0880 - acc: 0.9792 - val_loss: 0.3135 - val_acc: 0.8824\n",
      "Epoch 40/40\n",
      "15000/15000 [==============================] - 1s 46us/step - loss: 0.0845 - acc: 0.9804 - val_loss: 0.3173 - val_acc: 0.8820\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,partial_y_train,epochs=40,batch_size=512,validation_data=(x_val, y_val),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 53us/step\n",
      "[0.3391019322729111, 0.87184]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data, test_labels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create a graph of accuracy and loss over time\n",
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "_=plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "_=plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "_=plt.title('Training and validation loss')\n",
    "_=plt.xlabel('Epochs')\n",
    "_=plt.ylabel('Loss')\n",
    "_=plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "_=plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "_=plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "_=plt.title('Training and validation accuracy')\n",
    "_=plt.xlabel('Epochs')\n",
    "_=plt.ylabel('Accuracy')\n",
    "_=plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNs for Hand-written digit recognition using Tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-29-0f4d85f83c82>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /root/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /root/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /root/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /root/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /root/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "training_steps = 10000\n",
    "batch_size = 128\n",
    "display_step = 200\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 28 # MNIST data input (img shape: 28*28)\n",
    "timesteps = 28 # timesteps\n",
    "num_hidden = 128 # hidden layer num of features\n",
    "num_classes = 10 # MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-20-fa377b864ca9>:11: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n"
     ]
    }
   ],
   "source": [
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "logits = RNN(X, weights, biases)\n",
    "prediction = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-21-2a3808ee1525>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 2.8262, Training Accuracy= 0.094\n",
      "Step 200, Minibatch Loss= 2.1907, Training Accuracy= 0.273\n",
      "Step 400, Minibatch Loss= 1.9862, Training Accuracy= 0.367\n",
      "Step 600, Minibatch Loss= 1.7406, Training Accuracy= 0.445\n",
      "Step 800, Minibatch Loss= 1.7421, Training Accuracy= 0.406\n",
      "Step 1000, Minibatch Loss= 1.6670, Training Accuracy= 0.445\n",
      "Step 1200, Minibatch Loss= 1.4512, Training Accuracy= 0.578\n",
      "Step 1400, Minibatch Loss= 1.3966, Training Accuracy= 0.555\n",
      "Step 1600, Minibatch Loss= 1.3251, Training Accuracy= 0.578\n",
      "Step 1800, Minibatch Loss= 1.2412, Training Accuracy= 0.672\n",
      "Step 2000, Minibatch Loss= 1.4653, Training Accuracy= 0.523\n",
      "Step 2200, Minibatch Loss= 1.2625, Training Accuracy= 0.625\n",
      "Step 2400, Minibatch Loss= 1.1086, Training Accuracy= 0.656\n",
      "Step 2600, Minibatch Loss= 1.1803, Training Accuracy= 0.586\n",
      "Step 2800, Minibatch Loss= 1.2068, Training Accuracy= 0.648\n",
      "Step 3000, Minibatch Loss= 1.0966, Training Accuracy= 0.602\n",
      "Step 3200, Minibatch Loss= 1.0938, Training Accuracy= 0.648\n",
      "Step 3400, Minibatch Loss= 1.0280, Training Accuracy= 0.703\n",
      "Step 3600, Minibatch Loss= 0.8587, Training Accuracy= 0.727\n",
      "Step 3800, Minibatch Loss= 0.9175, Training Accuracy= 0.703\n",
      "Step 4000, Minibatch Loss= 1.1142, Training Accuracy= 0.625\n",
      "Step 4200, Minibatch Loss= 0.9162, Training Accuracy= 0.719\n",
      "Step 4400, Minibatch Loss= 0.7665, Training Accuracy= 0.797\n",
      "Step 4600, Minibatch Loss= 0.9672, Training Accuracy= 0.695\n",
      "Step 4800, Minibatch Loss= 0.7839, Training Accuracy= 0.797\n",
      "Step 5000, Minibatch Loss= 0.9768, Training Accuracy= 0.688\n",
      "Step 5200, Minibatch Loss= 0.7603, Training Accuracy= 0.766\n",
      "Step 5400, Minibatch Loss= 0.7815, Training Accuracy= 0.711\n",
      "Step 5600, Minibatch Loss= 0.8216, Training Accuracy= 0.734\n",
      "Step 5800, Minibatch Loss= 0.8705, Training Accuracy= 0.711\n",
      "Step 6000, Minibatch Loss= 0.7331, Training Accuracy= 0.766\n",
      "Step 6200, Minibatch Loss= 0.7908, Training Accuracy= 0.727\n",
      "Step 6400, Minibatch Loss= 0.6861, Training Accuracy= 0.820\n",
      "Step 6600, Minibatch Loss= 0.6176, Training Accuracy= 0.812\n",
      "Step 6800, Minibatch Loss= 0.6264, Training Accuracy= 0.805\n",
      "Step 7000, Minibatch Loss= 0.5177, Training Accuracy= 0.844\n",
      "Step 7200, Minibatch Loss= 0.5153, Training Accuracy= 0.867\n",
      "Step 7400, Minibatch Loss= 0.6004, Training Accuracy= 0.820\n",
      "Step 7600, Minibatch Loss= 0.7580, Training Accuracy= 0.773\n",
      "Step 7800, Minibatch Loss= 0.5191, Training Accuracy= 0.812\n",
      "Step 8000, Minibatch Loss= 0.6402, Training Accuracy= 0.812\n",
      "Step 8200, Minibatch Loss= 0.4759, Training Accuracy= 0.859\n",
      "Step 8400, Minibatch Loss= 0.5592, Training Accuracy= 0.820\n",
      "Step 8600, Minibatch Loss= 0.5339, Training Accuracy= 0.805\n",
      "Step 8800, Minibatch Loss= 0.4638, Training Accuracy= 0.875\n",
      "Step 9000, Minibatch Loss= 0.4750, Training Accuracy= 0.859\n",
      "Step 9200, Minibatch Loss= 0.4436, Training Accuracy= 0.844\n",
      "Step 9400, Minibatch Loss= 0.4236, Training Accuracy= 0.859\n",
      "Step 9600, Minibatch Loss= 0.5505, Training Accuracy= 0.812\n",
      "Step 9800, Minibatch Loss= 0.3732, Training Accuracy= 0.859\n",
      "Step 10000, Minibatch Loss= 0.5340, Training Accuracy= 0.844\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.8828125\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, training_steps+1):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Reshape data to get 28 seq of 28 elements\n",
    "        batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    "                                                                 Y: batch_y})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 128 mnist test images\n",
    "    test_len = 128\n",
    "    test_data = mnist.test.images[:test_len].reshape((-1, timesteps, num_input))\n",
    "    test_label = mnist.test.labels[:test_len]\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={X: test_data, Y: test_label}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-directional RNNs for Hand-written digit recognition using Tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "training_steps = 10000\n",
    "batch_size = 128\n",
    "display_step = 200\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 28 # MNIST data input (img shape: 28*28)\n",
    "timesteps = 28 # timesteps\n",
    "num_hidden = 128 # hidden layer num of features\n",
    "num_classes = 10 # MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    # Hidden layer weights => 2*n_hidden because of forward + backward cells\n",
    "    'out': tf.Variable(tf.random_normal([2*num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BiRNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, num_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, num_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define lstm cells with tensorflow\n",
    "    # Forward direction cell\n",
    "    lstm_fw_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "    # Backward direction cell\n",
    "    lstm_bw_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    try:\n",
    "        outputs, _, _ = rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,\n",
    "                                              dtype=tf.float32)\n",
    "    except Exception: # Old TensorFlow version only returns outputs not states\n",
    "        outputs = rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,\n",
    "                                        dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "logits = BiRNN(X, weights, biases)\n",
    "prediction = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 2.9396, Training Accuracy= 0.094\n",
      "Step 200, Minibatch Loss= 2.1005, Training Accuracy= 0.242\n",
      "Step 400, Minibatch Loss= 1.8750, Training Accuracy= 0.328\n",
      "Step 600, Minibatch Loss= 1.8338, Training Accuracy= 0.383\n",
      "Step 800, Minibatch Loss= 1.6140, Training Accuracy= 0.531\n",
      "Step 1000, Minibatch Loss= 1.5612, Training Accuracy= 0.453\n",
      "Step 1200, Minibatch Loss= 1.4795, Training Accuracy= 0.547\n",
      "Step 1400, Minibatch Loss= 1.5204, Training Accuracy= 0.523\n",
      "Step 1600, Minibatch Loss= 1.4288, Training Accuracy= 0.531\n",
      "Step 1800, Minibatch Loss= 1.3120, Training Accuracy= 0.562\n",
      "Step 2000, Minibatch Loss= 1.3247, Training Accuracy= 0.555\n",
      "Step 2200, Minibatch Loss= 1.1900, Training Accuracy= 0.578\n",
      "Step 2400, Minibatch Loss= 1.2392, Training Accuracy= 0.609\n",
      "Step 2600, Minibatch Loss= 1.2229, Training Accuracy= 0.609\n",
      "Step 2800, Minibatch Loss= 1.0204, Training Accuracy= 0.711\n",
      "Step 3000, Minibatch Loss= 0.8584, Training Accuracy= 0.766\n",
      "Step 3200, Minibatch Loss= 1.0449, Training Accuracy= 0.664\n",
      "Step 3400, Minibatch Loss= 0.9206, Training Accuracy= 0.727\n",
      "Step 3600, Minibatch Loss= 0.9660, Training Accuracy= 0.742\n",
      "Step 3800, Minibatch Loss= 0.8104, Training Accuracy= 0.750\n",
      "Step 4000, Minibatch Loss= 0.8363, Training Accuracy= 0.734\n",
      "Step 4200, Minibatch Loss= 0.9846, Training Accuracy= 0.680\n",
      "Step 4400, Minibatch Loss= 0.7567, Training Accuracy= 0.789\n",
      "Step 4600, Minibatch Loss= 0.8378, Training Accuracy= 0.719\n",
      "Step 4800, Minibatch Loss= 0.7488, Training Accuracy= 0.781\n",
      "Step 5000, Minibatch Loss= 0.8007, Training Accuracy= 0.758\n",
      "Step 5200, Minibatch Loss= 0.7024, Training Accuracy= 0.781\n",
      "Step 5400, Minibatch Loss= 0.7511, Training Accuracy= 0.766\n",
      "Step 5600, Minibatch Loss= 0.7060, Training Accuracy= 0.750\n",
      "Step 5800, Minibatch Loss= 0.7326, Training Accuracy= 0.750\n",
      "Step 6000, Minibatch Loss= 0.7654, Training Accuracy= 0.766\n",
      "Step 6200, Minibatch Loss= 0.5993, Training Accuracy= 0.820\n",
      "Step 6400, Minibatch Loss= 0.6489, Training Accuracy= 0.781\n",
      "Step 6600, Minibatch Loss= 0.5707, Training Accuracy= 0.828\n",
      "Step 6800, Minibatch Loss= 0.6204, Training Accuracy= 0.766\n",
      "Step 7000, Minibatch Loss= 0.4659, Training Accuracy= 0.836\n",
      "Step 7200, Minibatch Loss= 0.5876, Training Accuracy= 0.852\n",
      "Step 7400, Minibatch Loss= 0.6306, Training Accuracy= 0.828\n",
      "Step 7600, Minibatch Loss= 0.5046, Training Accuracy= 0.805\n",
      "Step 7800, Minibatch Loss= 0.5684, Training Accuracy= 0.836\n",
      "Step 8000, Minibatch Loss= 0.5750, Training Accuracy= 0.797\n",
      "Step 8200, Minibatch Loss= 0.4193, Training Accuracy= 0.891\n",
      "Step 8400, Minibatch Loss= 0.5913, Training Accuracy= 0.812\n",
      "Step 8600, Minibatch Loss= 0.5424, Training Accuracy= 0.812\n",
      "Step 8800, Minibatch Loss= 0.4278, Training Accuracy= 0.867\n",
      "Step 9000, Minibatch Loss= 0.3947, Training Accuracy= 0.898\n",
      "Step 9200, Minibatch Loss= 0.6035, Training Accuracy= 0.844\n",
      "Step 9400, Minibatch Loss= 0.5127, Training Accuracy= 0.852\n",
      "Step 9600, Minibatch Loss= 0.3670, Training Accuracy= 0.875\n",
      "Step 9800, Minibatch Loss= 0.4006, Training Accuracy= 0.875\n",
      "Step 10000, Minibatch Loss= 0.3452, Training Accuracy= 0.898\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.8828125\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, training_steps+1):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Reshape data to get 28 seq of 28 elements\n",
    "        batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    "                                                                 Y: batch_y})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 128 mnist test images\n",
    "    test_len = 128\n",
    "    test_data = mnist.test.images[:test_len].reshape((-1, timesteps, num_input))\n",
    "    test_label = mnist.test.labels[:test_len]\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={X: test_data, Y: test_label}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next word prediction using RNNs\n",
    "\n",
    "https://github.com/roatienza/Deep-Learning-Experiments/blob/master/Experiments/Tensorflow/RNN/rnn_words.py\n",
    "\n",
    "https://towardsdatascience.com/lstm-by-example-using-tensorflow-feb0c1968537"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next word prediction after n_input words learned from text file.\n",
    "A story is automatically generated if the predicted word is fed back as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import random\n",
    "import collections\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "def elapsed(sec):\n",
    "    if sec<60:\n",
    "        return str(sec) + \" sec\"\n",
    "    elif sec<(60*60):\n",
    "        return str(sec/60) + \" min\"\n",
    "    else:\n",
    "        return str(sec/(60*60)) + \" hr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target log path\n",
    "logs_path = 'logs/'\n",
    "writer = tf.summary.FileWriter(logs_path)\n",
    "\n",
    "# Text file containing words for training\n",
    "training_file = 'belling_the_cat.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded training data...\n"
     ]
    }
   ],
   "source": [
    "def read_data(fname):\n",
    "    with open(fname) as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "    content = [word for i in range(len(content)) for word in content[i].split()]\n",
    "    content = np.array(content)\n",
    "    return content\n",
    "\n",
    "training_data = read_data(training_file)\n",
    "print(\"Loaded training data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words):\n",
    "    count = collections.Counter(words).most_common()\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return dictionary, reverse_dictionary\n",
    "\n",
    "dictionary, reverse_dictionary = build_dataset(training_data)\n",
    "vocab_size = len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 50000\n",
    "display_step = 1000\n",
    "#In this example, the LSTM feeds on a sequence of 3 integers (eg 1x3 vector of int) \n",
    "#and tries to predict the 4th word.\n",
    "\n",
    "n_input = 3\n",
    "\n",
    "# number of units in RNN cell\n",
    "n_hidden = 512\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input, 1])\n",
    "y = tf.placeholder(\"float\", [None, vocab_size])\n",
    "\n",
    "# RNN output node weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, vocab_size]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([vocab_size]))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # reshape to [1, n_input]\n",
    "    x = tf.reshape(x, [-1, n_input])\n",
    "\n",
    "    # Generate a n_input-element sequence of inputs\n",
    "    # (eg. [had] [a] [general] -> [20] [6] [33])\n",
    "    x = tf.split(x,n_input,1)\n",
    "\n",
    "    # 2-layer LSTM, each layer has n_hidden units.\n",
    "    # Average Accuracy= 95.20% at 50k iter\n",
    "    rnn_cell = rnn.MultiRNNCell([rnn.BasicLSTMCell(n_hidden),rnn.BasicLSTMCell(n_hidden)])\n",
    "\n",
    "    # 1-layer LSTM with n_hidden units but with lower accuracy.\n",
    "    # Average Accuracy= 90.60% 50k iter\n",
    "    # Uncomment line below to test but comment out the 2-layer rnn.MultiRNNCell above\n",
    "    # rnn_cell = rnn.BasicLSTMCell(n_hidden)\n",
    "\n",
    "    # generate prediction\n",
    "    outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # there are n_input outputs but\n",
    "    # we only want the last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "pred = RNN(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Model evaluation\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 1000, Average Loss= 4.414061, Average Accuracy= 5.70%\n",
      "['nobody', 'spoke', '.'] - [then] vs [then]\n",
      "Iter= 2000, Average Loss= 2.868560, Average Accuracy= 22.20%\n",
      "['all', 'very', 'well'] - [,] vs [general]\n",
      "Iter= 3000, Average Loss= 2.461272, Average Accuracy= 36.50%\n",
      "['the', 'neighbourhood', '.'] - [this] vs [to]\n",
      "Iter= 4000, Average Loss= 2.258305, Average Accuracy= 39.80%\n",
      "['she', 'was', 'about'] - [,] vs [,]\n",
      "Iter= 5000, Average Loss= 1.830044, Average Accuracy= 53.60%\n",
      "['cat', '.', 'by'] - [this] vs [this]\n",
      "Iter= 6000, Average Loss= 1.754817, Average Accuracy= 57.90%\n",
      "[',', 'and', 'attached'] - [by] vs [by]\n",
      "Iter= 7000, Average Loss= 1.523224, Average Accuracy= 60.80%\n",
      "['of', 'her', 'approach'] - [,] vs [,]\n",
      "Iter= 8000, Average Loss= 1.295202, Average Accuracy= 66.00%\n",
      "['the', 'sly', 'and'] - [treacherous] vs [treacherous]\n",
      "Iter= 9000, Average Loss= 1.041020, Average Accuracy= 72.60%\n",
      "['said', 'he', 'had'] - [a] vs [a]\n",
      "Iter= 10000, Average Loss= 1.262483, Average Accuracy= 66.90%\n",
      "['that', 'but', 'at'] - [last] vs [last]\n",
      "Iter= 11000, Average Loss= 1.096972, Average Accuracy= 72.40%\n",
      "['enemy', ',', 'the'] - [cat] vs [cat]\n",
      "Iter= 12000, Average Loss= 0.822956, Average Accuracy= 77.50%\n",
      "['general', 'council', 'to'] - [consider] vs [consider]\n",
      "Iter= 13000, Average Loss= 1.016524, Average Accuracy= 75.20%\n",
      "['old', 'mouse', 'said'] - [it] vs [it]\n",
      "Iter= 14000, Average Loss= 0.808794, Average Accuracy= 79.40%\n",
      "['and', 'nobody', 'spoke'] - [.] vs [.]\n",
      "Iter= 15000, Average Loss= 0.791693, Average Accuracy= 78.90%\n",
      "[',', 'but', 'who'] - [is] vs [is]\n",
      "Iter= 16000, Average Loss= 0.730864, Average Accuracy= 80.40%\n",
      "['she', 'was', 'in'] - [the] vs [,]\n",
      "Iter= 17000, Average Loss= 0.710102, Average Accuracy= 81.30%\n",
      "['we', 'should', 'always'] - [know] vs [know]\n",
      "Iter= 18000, Average Loss= 0.617813, Average Accuracy= 83.70%\n",
      "['escape', 'from', 'her'] - [.] vs [was]\n",
      "Iter= 19000, Average Loss= 0.706462, Average Accuracy= 81.30%\n",
      "[',', 'if', 'we'] - [could] vs [could]\n",
      "Iter= 20000, Average Loss= 0.616325, Average Accuracy= 82.80%\n",
      "['enemy', 'approaches', 'us'] - [.] vs [.]\n",
      "Iter= 21000, Average Loss= 0.476069, Average Accuracy= 86.70%\n",
      "['thought', 'would', 'meet'] - [the] vs [the]\n",
      "Iter= 22000, Average Loss= 0.630386, Average Accuracy= 82.70%\n",
      "['said', 'that', 'but'] - [at] vs [at]\n",
      "Iter= 23000, Average Loss= 0.592698, Average Accuracy= 83.20%\n",
      "['what', 'measures', 'they'] - [could] vs [could]\n",
      "Iter= 24000, Average Loss= 0.650086, Average Accuracy= 83.80%\n",
      "['long', 'ago', ','] - [the] vs [the]\n",
      "Iter= 25000, Average Loss= 0.623524, Average Accuracy= 83.80%\n",
      "['mice', 'looked', 'at'] - [one] vs [one]\n",
      "Iter= 26000, Average Loss= 0.636491, Average Accuracy= 83.80%\n",
      "['to', 'bell', 'the'] - [cat] vs [cat]\n",
      "Iter= 27000, Average Loss= 0.520633, Average Accuracy= 87.30%\n",
      "['very', 'well', ','] - [but] vs [but]\n",
      "Iter= 28000, Average Loss= 0.610263, Average Accuracy= 86.00%\n",
      "[',', 'until', 'an'] - [old] vs [old]\n",
      "Iter= 29000, Average Loss= 0.441560, Average Accuracy= 88.20%\n",
      "['was', 'about', ','] - [and] vs [and]\n",
      "Iter= 30000, Average Loss= 0.574069, Average Accuracy= 84.70%\n",
      "['when', 'she', 'was'] - [about] vs [about]\n",
      "Iter= 31000, Average Loss= 0.641481, Average Accuracy= 84.20%\n",
      "['the', 'cat', '.'] - [by] vs [some]\n",
      "Iter= 32000, Average Loss= 0.555294, Average Accuracy= 86.40%\n",
      "['and', 'attached', 'by'] - [a] vs [a]\n",
      "Iter= 33000, Average Loss= 0.498478, Average Accuracy= 87.00%\n",
      "['her', '.', 'i'] - [venture] vs [venture]\n",
      "Iter= 34000, Average Loss= 0.418984, Average Accuracy= 88.30%\n",
      "['manner', 'in', 'which'] - [the] vs [the]\n",
      "Iter= 35000, Average Loss= 0.519121, Average Accuracy= 86.70%\n",
      "['he', ',', 'that'] - [our] vs [our]\n",
      "Iter= 36000, Average Loss= 0.476838, Average Accuracy= 87.30%\n",
      "['make', ',', 'which'] - [he] vs [he]\n",
      "Iter= 37000, Average Loss= 0.293020, Average Accuracy= 91.60%\n",
      "['outwit', 'their', 'common'] - [enemy] vs [enemy]\n",
      "Iter= 38000, Average Loss= 0.421553, Average Accuracy= 89.50%\n",
      "['a', 'general', 'council'] - [to] vs [to]\n",
      "Iter= 39000, Average Loss= 0.507681, Average Accuracy= 88.00%\n",
      "['then', 'the', 'old'] - [mouse] vs [mouse]\n",
      "Iter= 40000, Average Loss= 0.547676, Average Accuracy= 86.50%\n",
      "['another', 'and', 'nobody'] - [spoke] vs [spoke]\n",
      "Iter= 41000, Average Loss= 0.408786, Average Accuracy= 90.40%\n",
      "['old', 'mouse', 'got'] - [up] vs [up]\n",
      "Iter= 42000, Average Loss= 0.385947, Average Accuracy= 90.30%\n",
      "['this', 'proposal', 'met'] - [with] vs [with]\n",
      "Iter= 43000, Average Loss= 0.377846, Average Accuracy= 91.50%\n",
      "['a', 'ribbon', 'round'] - [the] vs [the]\n",
      "Iter= 44000, Average Loss= 0.383351, Average Accuracy= 90.90%\n",
      "['a', 'small', 'bell'] - [be] vs [be]\n",
      "Iter= 45000, Average Loss= 0.408638, Average Accuracy= 90.30%\n",
      "['venture', ',', 'therefore'] - [,] vs [,]\n",
      "Iter= 46000, Average Loss= 0.513189, Average Accuracy= 88.90%\n",
      "['could', 'receive', 'some'] - [signal] vs [signal]\n",
      "Iter= 47000, Average Loss= 0.424288, Average Accuracy= 89.90%\n",
      "['said', 'he', ','] - [that] vs [and]\n",
      "Iter= 48000, Average Loss= 0.440598, Average Accuracy= 90.10%\n",
      "[',', 'which', 'he'] - [thought] vs [thought]\n",
      "Iter= 49000, Average Loss= 0.494948, Average Accuracy= 89.30%\n",
      "['last', 'a', 'young'] - [mouse] vs [mouse]\n",
      "Iter= 50000, Average Loss= 0.507042, Average Accuracy= 89.90%\n",
      "['outwit', 'their', 'common'] - [enemy] vs [enemy]\n",
      "Optimization Finished!\n",
      "Elapsed time:  25.03334660132726 min\n",
      "Run on command line.\n",
      "\ttensorboard --logdir=logs/\n",
      "Point your web browser to: http://localhost:6006/\n",
      "3 words: a general council\n",
      "a general council to consider what measures enemy , the cat . some said this , and some said that but at last a young mouse got up and said that is all very well\n",
      "3 words: mouse mouse mouse\n",
      "mouse mouse mouse council escape . now , if we could receive escape danger consists consists in the sly and treacherous manner in the sly and treacherous manner in the sly and treacherous manner in\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    step = 0\n",
    "    offset = random.randint(0,n_input+1)\n",
    "    end_offset = n_input + 1\n",
    "    acc_total = 0\n",
    "    loss_total = 0\n",
    "\n",
    "    writer.add_graph(session.graph)\n",
    "\n",
    "    while step < training_iters:\n",
    "        # Generate a minibatch. Add some randomness on selection process.\n",
    "        if offset > (len(training_data)-end_offset):\n",
    "            offset = random.randint(0, n_input+1)\n",
    "\n",
    "        symbols_in_keys = [ [dictionary[ str(training_data[i])]] for i in range(offset, offset+n_input) ]\n",
    "        symbols_in_keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n",
    "\n",
    "        symbols_out_onehot = np.zeros([vocab_size], dtype=float)\n",
    "        symbols_out_onehot[dictionary[str(training_data[offset+n_input])]] = 1.0\n",
    "        symbols_out_onehot = np.reshape(symbols_out_onehot,[1,-1])\n",
    "\n",
    "        _, acc, loss, onehot_pred = session.run([optimizer, accuracy, cost, pred], \\\n",
    "                                                feed_dict={x: symbols_in_keys, y: symbols_out_onehot})\n",
    "        loss_total += loss\n",
    "        acc_total += acc\n",
    "        if (step+1) % display_step == 0:\n",
    "            print(\"Iter= \" + str(step+1) + \", Average Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss_total/display_step) + \", Average Accuracy= \" + \\\n",
    "                  \"{:.2f}%\".format(100*acc_total/display_step))\n",
    "            acc_total = 0\n",
    "            loss_total = 0\n",
    "            symbols_in = [training_data[i] for i in range(offset, offset + n_input)]\n",
    "            symbols_out = training_data[offset + n_input]\n",
    "            symbols_out_pred = reverse_dictionary[int(tf.argmax(onehot_pred, 1).eval())]\n",
    "            print(\"%s - [%s] vs [%s]\" % (symbols_in,symbols_out,symbols_out_pred))\n",
    "        step += 1\n",
    "        offset += (n_input+1)\n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Elapsed time: \", elapsed(time.time() - start_time))\n",
    "    print(\"Run on command line.\")\n",
    "    print(\"\\ttensorboard --logdir=%s\" % (logs_path))\n",
    "    print(\"Point your web browser to: http://localhost:6006/\")\n",
    "    while True:\n",
    "        prompt = \"%s words: \" % n_input\n",
    "        sentence = input(prompt)\n",
    "        sentence = sentence.strip()\n",
    "        words = sentence.split(' ')\n",
    "        if len(words) != n_input:\n",
    "            continue\n",
    "        try:\n",
    "            symbols_in_keys = [dictionary[str(words[i])] for i in range(len(words))]\n",
    "            for i in range(32):\n",
    "                keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n",
    "                onehot_pred = session.run(pred, feed_dict={x: keys})\n",
    "                onehot_pred_index = int(tf.argmax(onehot_pred, 1).eval())\n",
    "                sentence = \"%s %s\" % (sentence,reverse_dictionary[onehot_pred_index])\n",
    "                symbols_in_keys = symbols_in_keys[1:]\n",
    "                symbols_in_keys.append(onehot_pred_index)\n",
    "            print(sentence)\n",
    "        except:\n",
    "            print(\"Word not in dictionary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock market sentiment prediction using RNNs in TensorFlow\n",
    "\n",
    "https://www.oreilly.com/ideas/introduction-to-lstms-with-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_ST_message(text):\n",
    "    \"\"\"\n",
    "    Preprocesses raw message data for analysis\n",
    "    :param text: String. ST Message\n",
    "    :return: List of Strings.  List of processed text tokes\n",
    "    \"\"\"\n",
    "    # Define ST Regex Patters\n",
    "    REGEX_PRICE_SIGN = re.compile(r'\\$(?!\\d*\\.?\\d+%)\\d*\\.?\\d+|(?!\\d*\\.?\\d+%)\\d*\\.?\\d+\\$')\n",
    "    REGEX_PRICE_NOSIGN = re.compile(r'(?!\\d*\\.?\\d+%)(?!\\d*\\.?\\d+k)\\d*\\.?\\d+')\n",
    "    REGEX_TICKER = re.compile('\\$[a-zA-Z]+')\n",
    "    REGEX_USER = re.compile('\\@\\w+')\n",
    "    REGEX_LINK = re.compile('https?:\\/\\/[^\\s]+')\n",
    "    REGEX_HTML_ENTITY = re.compile('\\&\\w+')\n",
    "    REGEX_NON_ACSII = re.compile('[^\\x00-\\x7f]')\n",
    "    REGEX_PUNCTUATION = re.compile('[%s]' % re.escape(string.punctuation.replace('<', '')).replace('>', ''))\n",
    "    REGEX_NUMBER = re.compile(r'[-+]?[0-9]+')\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    # Replace ST \"entitites\" with a unique token\n",
    "    text = re.sub(REGEX_TICKER, ' <TICKER> ', text)\n",
    "    text = re.sub(REGEX_USER, ' <USER> ', text)\n",
    "    text = re.sub(REGEX_LINK, ' <LINK> ', text)\n",
    "    text = re.sub(REGEX_PRICE_SIGN, ' <PRICE> ', text)\n",
    "    text = re.sub(REGEX_PRICE_NOSIGN, ' <NUMBER> ', text)\n",
    "    text = re.sub(REGEX_NUMBER, ' <NUMBER> ', text)\n",
    "    # Remove extraneous text data\n",
    "    text = re.sub(REGEX_HTML_ENTITY, \"\", text)\n",
    "    text = re.sub(REGEX_NON_ACSII, \"\", text)\n",
    "    text = re.sub(REGEX_PUNCTUATION, \"\", text)\n",
    "    # Tokenize and remove < and > that are not in special tokens\n",
    "    words = \" \".join(token.replace(\"<\", \"\").replace(\">\", \"\")\n",
    "                     if token not in ['<TICKER>', '<USER>', '<LINK>', '<PRICE>', '<NUMBER>']\n",
    "                     else token\n",
    "                     for token\n",
    "                     in text.split())\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lookup_tables(words):\n",
    "    \"\"\"\n",
    "    Create lookup tables for vocabulary\n",
    "    :param words: Input list of words\n",
    "    :return: A tuple of dicts.  The first dict maps a vocab word to and integeter\n",
    "             The second maps an integer back to to the vocab word\n",
    "    \"\"\"\n",
    "    word_counts = Counter(words)\n",
    "    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "    int_to_vocab = {ii: word for ii, word in enumerate(sorted_vocab, 1)}\n",
    "    vocab_to_int = {word: ii for ii, word in int_to_vocab.items()}\n",
    "\n",
    "    return vocab_to_int, int_to_vocab\n",
    "\n",
    "def encode_ST_messages(messages, vocab_to_int):\n",
    "    \"\"\"\n",
    "    Encode ST Sentiment Labels\n",
    "    :param messages: list of list of strings. List of message tokens\n",
    "    :param vocab_to_int: mapping of vocab to idx\n",
    "    :return: list of ints. Lists of encoded messages\n",
    "    \"\"\"\n",
    "    messages_encoded = []\n",
    "    for message in messages:\n",
    "        messages_encoded.append([vocab_to_int[word] for word in message.split()])\n",
    "\n",
    "    return np.array(messages_encoded)\n",
    "\n",
    "def encode_ST_labels(labels):\n",
    "    \"\"\"\n",
    "    Encode ST Sentiment Labels\n",
    "    :param labels: Input list of labels\n",
    "    :return: numpy array.  The encoded labels\n",
    "    \"\"\"\n",
    "    return np.array([1 if sentiment == 'bullish' else 0 for sentiment in labels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_empty_messages(messages, labels):\n",
    "    \"\"\"\n",
    "    Drop messages that are left empty after preprocessing\n",
    "    :param messages: list of encoded messages\n",
    "    :return: tuple of arrays. First array is non-empty messages, second array is non-empty labels\n",
    "    \"\"\"\n",
    "    non_zero_idx = [ii for ii, message in enumerate(messages) if len(message) != 0]\n",
    "    messages_non_zero = np.array([messages[ii] for ii in non_zero_idx])\n",
    "    labels_non_zero = np.array([labels[ii] for ii in non_zero_idx])\n",
    "    return messages_non_zero, labels_non_zero\n",
    "\n",
    "def zero_pad_messages(messages, seq_len):\n",
    "    \"\"\"\n",
    "    Zero Pad input messages\n",
    "    :param messages: Input list of encoded messages\n",
    "    :param seq_ken: Input int, maximum sequence input length\n",
    "    :return: numpy array.  The encoded labels\n",
    "    \"\"\"\n",
    "    messages_padded = np.zeros((len(messages), seq_len), dtype=int)\n",
    "    for i, row in enumerate(messages):\n",
    "        messages_padded[i, -len(row):] = np.array(row)[:seq_len]\n",
    "\n",
    "    return np.array(messages_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(messages, labels, split_frac, random_seed=None):\n",
    "    \"\"\"\n",
    "    Zero Pad input messages\n",
    "    :param messages: Input list of encoded messages\n",
    "    :param labels: Input list of encoded labels\n",
    "    :param split_frac: Input float, training split percentage\n",
    "    :return: tuple of arrays train_x, val_x, test_x, train_y, val_y, test_y\n",
    "    \"\"\"\n",
    "    # make sure that number of messages and labels allign\n",
    "    assert len(messages) == len(labels)\n",
    "    # random shuffle data\n",
    "    if random_seed:\n",
    "        np.random.seed(random_seed)\n",
    "    shuf_idx = np.random.permutation(len(messages))\n",
    "    messages_shuf = np.array(messages)[shuf_idx] \n",
    "    labels_shuf = np.array(labels)[shuf_idx]\n",
    "\n",
    "    #make splits\n",
    "    split_idx = int(len(messages_shuf)*split_frac)\n",
    "    train_x, val_x = messages_shuf[:split_idx], messages_shuf[split_idx:]\n",
    "    train_y, val_y = labels_shuf[:split_idx], labels_shuf[split_idx:]\n",
    "\n",
    "    test_idx = int(len(val_x)*0.5)\n",
    "    val_x, test_x = val_x[:test_idx], val_x[test_idx:]\n",
    "    val_y, test_y = val_y[:test_idx], val_y[test_idx:]\n",
    "\n",
    "    return train_x, val_x, test_x, train_y, val_y, test_y\n",
    "    \n",
    "def get_batches(x, y, batch_size=100):\n",
    "    \"\"\"\n",
    "    Batch Generator for Training\n",
    "    :param x: Input array of x data\n",
    "    :param y: Input array of y data\n",
    "    :param batch_size: Input int, size of batch\n",
    "    :return: generator that returns a tuple of our x batch and y batch\n",
    "    \"\"\"\n",
    "    n_batches = len(x)//batch_size\n",
    "    x, y = x[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "    for ii in range(0, len(x), batch_size):\n",
    "        yield x[ii:ii+batch_size], y[ii:ii+batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Stock Market Sentiment with LSTMs and TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will build a Long Short Term Memory (LSTM) Network to predict the stock market sentiment based on a comment about the market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following libraries for our analysis:\n",
    "\n",
    "* numpy - numerical computing library used to work with our data\n",
    "* pandas - data analysis library used to read in our data from csv\n",
    "* tensorflow - deep learning framework used for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also be using the python Counter object for counting our vocabulary items and we have a util module that extracts away a lot of the details of our data processing. Please read through the util.py to get a better understanding of how to preprocess the data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import utils as utl\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train the model using messages tagged with SPY, the S&P 500 index fund, from [StockTwits.com](https://www.stocktwits.com). StockTwits is a social media network for traders and investors to share their views about the stock market. When a user posts a message, they tag the relevant stock ticker ($SPY in our case) and have the option to tag the messages with their sentiment – “bullish” if they believe the stock will go up and “bearish” if they believe the stock will go down.\n",
    "\n",
    "Our dataset consists of approximately 100,000 messages posted in 2017 that are tagged with $SPY where the user indicated their sentiment. Before we get to our LSTM Network we have to perform some processing on our data to get it ready for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read and View Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we simply read in our data using pandas, pull out our message and sentiment data into numpy arrays. Let's also take a look at a few samples to get familiar with the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messages: $SPY crazy day so far!... Sentiment: bearish\n",
      "Messages: $SPY Will make a new ATH this week. Watch it!... Sentiment: bullish\n",
      "Messages: $SPY $DJIA white elephant in room is $AAPL. Up 14% since election. Strong headwinds w/Trump trade & Strong dollar. How many 7's do you see?... Sentiment: bearish\n",
      "Messages: $SPY blocks above. We break above them We should push to double top... Sentiment: bullish\n",
      "Messages: $SPY Nothing happening in the market today, guess I'll go to the store and spend some $.... Sentiment: bearish\n",
      "Messages: $SPY What an easy call. Good jobs report: good economy, markets go up.  Bad jobs report: no more rate hikes, markets go up.  Win-win.... Sentiment: bullish\n",
      "Messages: $SPY BS market.... Sentiment: bullish\n",
      "Messages: $SPY this rally all the cheerleaders were screaming about this morning is pretty weak. I keep adding 2 my short at all spikes... Sentiment: bearish\n",
      "Messages: $SPY Dollar ripping higher!... Sentiment: bearish\n",
      "Messages: $SPY no reason to go down !... Sentiment: bullish\n"
     ]
    }
   ],
   "source": [
    "# read data from csv file\n",
    "data = pd.read_csv(\"data/StockTwits_SPY_Sentiment_2017.gz\",\n",
    "                   encoding=\"utf-8\",\n",
    "                   compression=\"gzip\",\n",
    "                   index_col=0)\n",
    "\n",
    "# get messages and sentiment labels\n",
    "messages = data.message.values\n",
    "labels = data.sentiment.values\n",
    "\n",
    "# View sample of messages with sentiment\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Messages: {}...\".format(messages[i]),\n",
    "          \"Sentiment: {}\".format(labels[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with raw text data often requires preprocessing the text in some fashion to normalize for context. In our case we want to normalize for known unique \"entities\" that appear within messages that carry a similar contextual meaning when analyzing sentiment. This means we want to replace references to specific stock tickers, user names, url links or numbers with a special token identifying the \"entity\". Here we will also make everything lower case and remove punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "messages = np.array([utl.preprocess_ST_message(message) for message in messages])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Vocab to Index Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with raw text we need some encoding from words to numbers for our algorithm to work with the inputs. The first step of doing this is keeping a collection of our full vocabularly and creating a mapping of each word to a unique index. We will use this word to index mapping in a little bit to prep out messages for analysis. \n",
    "\n",
    "Note that in practice we may want to only include the vocabularly from our training set here to account for the fact that we will likely see new words when our model is out in the wild when we are assessing the results on our validation and test sets. Here, for simplicity and demonstration purposes, we will use our entire data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_lexicon = \" \".join(messages).split()\n",
    "vocab_to_int, int_to_vocab = utl.create_lookup_tables(full_lexicon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Message Lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also want to get a sense of the distribution of the length of our inputs. We check for the longest and average messages. We will need to make our input length uniform to feed the data into our model so later we will have some decisions to make about possibly truncating some of the longer messages if they are too long. We also notice that one message has no content remaining after we preprocessed the data, so we will remove this message from our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-length messages: 1\n",
      "Maximum message length: 244\n",
      "Average message length: 78.21856920395598\n"
     ]
    }
   ],
   "source": [
    "messages_lens = Counter([len(x) for x in messages])\n",
    "print(\"Zero-length messages: {}\".format(messages_lens[0]))\n",
    "print(\"Maximum message length: {}\".format(max(messages_lens)))\n",
    "print(\"Average message length: {}\".format(np.mean([len(x) for x in messages])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "messages, labels = utl.drop_empty_messages(messages, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode Messages and Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier we mentioned that we need to \"translate\" our text to number for our algorithm to take in as inputs. We call this translation an encoding. We encode our messages to sequences of numbers where each nummber is the word index from the mapping we made earlier. The phrase \"I am bullish\" would now look something like [1, 234, 5345] where each number is the index for the respective word in the message. For our sentiment labels we will simply encode \"bearish\" as 0 and \"bullish\" as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "messages = utl.encode_ST_messages(messages, vocab_to_int)\n",
    "labels = utl.encode_ST_labels(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pad Messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we need to do is make our message inputs the same length. In our case, the longest message is 244 words. LSTMs can usually handle sequence inputs up to 500 items in length so we won't truncate any of the messages here. We need to Zero Pad the rest of the messages that are shorter. We will use a left padding that will pad all of the messages that are shorter than 244 words with 0s at the beginning. So our encoded \"I am bullish\" messages goes from [1, 234, 5345] (length 3) to [0, 0, 0, 0, 0, 0, ... , 0, 0, 1, 234, 5345] (length 244)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "messages = utl.zero_pad_messages(messages, seq_len=244)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train, Test, Validation Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we do is split our data into tranining, validation and test sets and observe the size of each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Set Size\n",
      "Train set: \t\t(77572, 244) \n",
      "Validation set: \t(9697, 244) \n",
      "Test set: \t\t(9697, 244)\n"
     ]
    }
   ],
   "source": [
    "train_x, val_x, test_x, train_y, val_y, test_y = utl.train_val_test_split(messages, labels, split_frac=0.80)\n",
    "\n",
    "print(\"Data Set Size\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and Training our LSTM Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will define a number of functions that will construct the items in our network. We will then use these functions to build and train our network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we simply define a function to build TensorFlow Placeholders for our message sequences, our labels and a variable called keep probability associated with drop out (we will talk more about this later). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_inputs():\n",
    "    \"\"\"\n",
    "    Create the model inputs\n",
    "    \"\"\"\n",
    "    inputs_ = tf.placeholder(tf.int32, [None, None], name='inputs')\n",
    "    labels_ = tf.placeholder(tf.int32, [None, None], name='labels')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    return inputs_, labels_, keep_prob_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In TensorFlow the word embeddings are represented as a vocabulary size x embedding size matrix and will learn these weights during our training process. The embedding lookup is then just a simple lookup from our embedding matrix based on the index of the current word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_embedding_layer(inputs_, vocab_size, embed_size):\n",
    "    \"\"\"\n",
    "    Create the embedding layer\n",
    "    \"\"\"\n",
    "    embedding = tf.Variable(tf.random_uniform((vocab_size, embed_size), -1, 1))\n",
    "    embed = tf.nn.embedding_lookup(embedding, inputs_)\n",
    "    \n",
    "    return embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow makes it extremely easy to build LSTM Layers and stack them on top of each other. We represent each LSTM layer as a BasicLSTMCell and keep these in a list to stack them together later. Here we will define a list with our LSTM layer sizes and the number of layers. \n",
    "\n",
    "We then take each of these LSTM layers and wrap them in a Dropout Layer. Dropout is a regularization technique using in Neural Networks in which any individual node has a probability of “dropping out” of the network during a given iteration of learning. The makes the model more generalizable by ensuring that it is not too dependent on any given nodes. \n",
    "\n",
    "Finally, we stack these layers using a MultiRNNCell, generate a zero initial state and connect our stacked LSTM layer to our word embedding inputs using dynamic_rnn. Here we track the output and the final state of the LSTM cell, which we will need to pass between mini-batches during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_lstm_layers(lstm_sizes, embed, keep_prob_, batch_size):\n",
    "    \"\"\"\n",
    "    Create the LSTM layers\n",
    "    \"\"\"\n",
    "    lstms = [tf.contrib.rnn.BasicLSTMCell(size) for size in lstm_sizes]\n",
    "    # Add dropout to the cell\n",
    "    drops = [tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob_) for lstm in lstms]\n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    cell = tf.contrib.rnn.MultiRNNCell(drops)\n",
    "    # Getting an initial state of all zeros\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "    \n",
    "    lstm_outputs, final_state = tf.nn.dynamic_rnn(cell, embed, initial_state=initial_state)\n",
    "    \n",
    "    return initial_state, lstm_outputs, cell, final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we get our predictions by passing the final output of the LSTM layers to a sigmoid activation function via a Tensorflow fully connected layer.  we only care to use the final output for making predictions so we pull this out using the [: , -1] indexing on our LSTM outputs and pass it through a sigmoid activation function to make the predictions. We pass then pass these predictions to our mean squared error loss function and use the Adadelta Optimizer to minimize the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_cost_fn_and_opt(lstm_outputs, labels_, learning_rate):\n",
    "    \"\"\"\n",
    "    Create the Loss function and Optimizer\n",
    "    \"\"\"\n",
    "    predictions = tf.contrib.layers.fully_connected(lstm_outputs[:, -1], 1, activation_fn=tf.sigmoid)\n",
    "    loss = tf.losses.mean_squared_error(labels_, predictions)\n",
    "    optimzer = tf.train.AdadeltaOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    return predictions, loss, optimzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define our accuracy metric for assessing the model performance across our training, validation and test sets. Even though accuracy is just a calculation based on results, everything in TensorFlow is part of a Computation Graph. Therefore, we need to define our loss and accuracy nodes in the context of the rest of our network graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_accuracy(predictions, labels_):\n",
    "    \"\"\"\n",
    "    Create accuracy\n",
    "    \"\"\"\n",
    "    correct_pred = tf.equal(tf.cast(tf.round(predictions), tf.int32), labels_)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are finally ready to build and train our LSTM Network! First, we call each of our each of the functions we have defined to construct the network. Then we define a Saver to be able to write our model to disk to load for future use. Finally, we call a Tensorflow Session to train the model over a predefined number of epochs using mini-batches. At the end of each epoch we will print the loss, training accuracy and validation accuracy to monitor the results as we train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_and_train_network(lstm_sizes, vocab_size, embed_size, epochs, batch_size,\n",
    "                            learning_rate, keep_prob, train_x, val_x, train_y, val_y):\n",
    "    \n",
    "    inputs_, labels_, keep_prob_ = model_inputs()\n",
    "    embed = build_embedding_layer(inputs_, vocab_size, embed_size)\n",
    "    initial_state, lstm_outputs, lstm_cell, final_state = build_lstm_layers(lstm_sizes, embed, keep_prob_, batch_size)\n",
    "    predictions, loss, optimizer = build_cost_fn_and_opt(lstm_outputs, labels_, learning_rate)\n",
    "    accuracy = build_accuracy(predictions, labels_)\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        n_batches = len(train_x)//batch_size\n",
    "        for e in range(epochs):\n",
    "            state = sess.run(initial_state)\n",
    "            \n",
    "            train_acc = []\n",
    "            for ii, (x, y) in enumerate(utl.get_batches(train_x, train_y, batch_size), 1):\n",
    "                feed = {inputs_: x,\n",
    "                        labels_: y[:, None],\n",
    "                        keep_prob_: keep_prob,\n",
    "                        initial_state: state}\n",
    "                loss_, state, _,  batch_acc = sess.run([loss, final_state, optimizer, accuracy], feed_dict=feed)\n",
    "                train_acc.append(batch_acc)\n",
    "                \n",
    "                if (ii + 1) % n_batches == 0:\n",
    "                    \n",
    "                    val_acc = []\n",
    "                    val_state = sess.run(lstm_cell.zero_state(batch_size, tf.float32))\n",
    "                    for xx, yy in utl.get_batches(val_x, val_y, batch_size):\n",
    "                        feed = {inputs_: xx,\n",
    "                                labels_: yy[:, None],\n",
    "                                keep_prob_: 1,\n",
    "                                initial_state: val_state}\n",
    "                        val_batch_acc, val_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "                        val_acc.append(val_batch_acc)\n",
    "                    \n",
    "                    print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                          \"Batch: {}/{}...\".format(ii+1, n_batches),\n",
    "                          \"Train Loss: {:.3f}...\".format(loss_),\n",
    "                          \"Train Accruacy: {:.3f}...\".format(np.mean(train_acc)),\n",
    "                          \"Val Accuracy: {:.3f}\".format(np.mean(val_acc)))\n",
    "    \n",
    "        saver.save(sess, \"checkpoints/sentiment.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define our model hyper parameters. We will build a 2 Layer LSTM Newtork with hidden layer sizes of 128 and 64 respectively. We will use an embedding size of 300 and train over 50 epochs with mini-batches of size 256. We will use an initial learning rate of 0.1, though our Adadelta Optimizer will adapt this over time, and a keep probability of 0.5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Inputs and Hyperparameters\n",
    "lstm_sizes = [128, 64]\n",
    "vocab_size = len(vocab_to_int) + 1 #add one for padding\n",
    "embed_size = 300\n",
    "epochs = 50\n",
    "batch_size = 256\n",
    "learning_rate = 0.1\n",
    "keep_prob = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and now we train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50... Batch: 303/303... Train Loss: 0.247... Train Accruacy: 0.562... Val Accuracy: 0.578\n",
      "Epoch: 2/50... Batch: 303/303... Train Loss: 0.245... Train Accruacy: 0.583... Val Accuracy: 0.596\n",
      "Epoch: 3/50... Batch: 303/303... Train Loss: 0.247... Train Accruacy: 0.597... Val Accuracy: 0.617\n",
      "Epoch: 4/50... Batch: 303/303... Train Loss: 0.240... Train Accruacy: 0.610... Val Accuracy: 0.627\n",
      "Epoch: 5/50... Batch: 303/303... Train Loss: 0.238... Train Accruacy: 0.620... Val Accuracy: 0.632\n",
      "Epoch: 6/50... Batch: 303/303... Train Loss: 0.234... Train Accruacy: 0.632... Val Accuracy: 0.642\n",
      "Epoch: 7/50... Batch: 303/303... Train Loss: 0.230... Train Accruacy: 0.636... Val Accuracy: 0.648\n",
      "Epoch: 8/50... Batch: 303/303... Train Loss: 0.227... Train Accruacy: 0.641... Val Accuracy: 0.653\n",
      "Epoch: 9/50... Batch: 303/303... Train Loss: 0.223... Train Accruacy: 0.646... Val Accuracy: 0.656\n",
      "Epoch: 10/50... Batch: 303/303... Train Loss: 0.221... Train Accruacy: 0.652... Val Accuracy: 0.659\n",
      "Epoch: 11/50... Batch: 303/303... Train Loss: 0.225... Train Accruacy: 0.656... Val Accuracy: 0.663\n",
      "Epoch: 12/50... Batch: 303/303... Train Loss: 0.220... Train Accruacy: 0.661... Val Accuracy: 0.666\n",
      "Epoch: 13/50... Batch: 303/303... Train Loss: 0.215... Train Accruacy: 0.665... Val Accuracy: 0.668\n",
      "Epoch: 14/50... Batch: 303/303... Train Loss: 0.213... Train Accruacy: 0.668... Val Accuracy: 0.670\n",
      "Epoch: 15/50... Batch: 303/303... Train Loss: 0.210... Train Accruacy: 0.669... Val Accuracy: 0.673\n",
      "Epoch: 16/50... Batch: 303/303... Train Loss: 0.213... Train Accruacy: 0.673... Val Accuracy: 0.675\n",
      "Epoch: 17/50... Batch: 303/303... Train Loss: 0.212... Train Accruacy: 0.675... Val Accuracy: 0.676\n",
      "Epoch: 18/50... Batch: 303/303... Train Loss: 0.206... Train Accruacy: 0.681... Val Accuracy: 0.679\n",
      "Epoch: 19/50... Batch: 303/303... Train Loss: 0.208... Train Accruacy: 0.683... Val Accuracy: 0.681\n",
      "Epoch: 20/50... Batch: 303/303... Train Loss: 0.202... Train Accruacy: 0.684... Val Accuracy: 0.684\n",
      "Epoch: 21/50... Batch: 303/303... Train Loss: 0.206... Train Accruacy: 0.685... Val Accuracy: 0.686\n",
      "Epoch: 22/50... Batch: 303/303... Train Loss: 0.204... Train Accruacy: 0.689... Val Accuracy: 0.689\n",
      "Epoch: 23/50... Batch: 303/303... Train Loss: 0.195... Train Accruacy: 0.690... Val Accuracy: 0.691\n",
      "Epoch: 24/50... Batch: 303/303... Train Loss: 0.200... Train Accruacy: 0.695... Val Accuracy: 0.692\n",
      "Epoch: 25/50... Batch: 303/303... Train Loss: 0.195... Train Accruacy: 0.696... Val Accuracy: 0.694\n",
      "Epoch: 26/50... Batch: 303/303... Train Loss: 0.200... Train Accruacy: 0.698... Val Accuracy: 0.695\n",
      "Epoch: 27/50... Batch: 303/303... Train Loss: 0.197... Train Accruacy: 0.701... Val Accuracy: 0.695\n",
      "Epoch: 28/50... Batch: 303/303... Train Loss: 0.199... Train Accruacy: 0.703... Val Accuracy: 0.698\n",
      "Epoch: 29/50... Batch: 303/303... Train Loss: 0.187... Train Accruacy: 0.704... Val Accuracy: 0.698\n",
      "Epoch: 30/50... Batch: 303/303... Train Loss: 0.190... Train Accruacy: 0.708... Val Accuracy: 0.701\n",
      "Epoch: 31/50... Batch: 303/303... Train Loss: 0.189... Train Accruacy: 0.708... Val Accuracy: 0.702\n",
      "Epoch: 32/50... Batch: 303/303... Train Loss: 0.184... Train Accruacy: 0.710... Val Accuracy: 0.704\n",
      "Epoch: 33/50... Batch: 303/303... Train Loss: 0.195... Train Accruacy: 0.714... Val Accuracy: 0.704\n",
      "Epoch: 34/50... Batch: 303/303... Train Loss: 0.190... Train Accruacy: 0.715... Val Accuracy: 0.704\n",
      "Epoch: 35/50... Batch: 303/303... Train Loss: 0.186... Train Accruacy: 0.714... Val Accuracy: 0.707\n",
      "Epoch: 36/50... Batch: 303/303... Train Loss: 0.178... Train Accruacy: 0.717... Val Accuracy: 0.707\n",
      "Epoch: 37/50... Batch: 303/303... Train Loss: 0.183... Train Accruacy: 0.722... Val Accuracy: 0.707\n",
      "Epoch: 38/50... Batch: 303/303... Train Loss: 0.181... Train Accruacy: 0.721... Val Accuracy: 0.710\n",
      "Epoch: 39/50... Batch: 303/303... Train Loss: 0.181... Train Accruacy: 0.723... Val Accuracy: 0.712\n",
      "Epoch: 40/50... Batch: 303/303... Train Loss: 0.179... Train Accruacy: 0.726... Val Accuracy: 0.712\n",
      "Epoch: 41/50... Batch: 303/303... Train Loss: 0.180... Train Accruacy: 0.726... Val Accuracy: 0.713\n",
      "Epoch: 42/50... Batch: 303/303... Train Loss: 0.177... Train Accruacy: 0.729... Val Accuracy: 0.714\n",
      "Epoch: 43/50... Batch: 303/303... Train Loss: 0.176... Train Accruacy: 0.731... Val Accuracy: 0.714\n",
      "Epoch: 44/50... Batch: 303/303... Train Loss: 0.180... Train Accruacy: 0.732... Val Accuracy: 0.716\n",
      "Epoch: 45/50... Batch: 303/303... Train Loss: 0.169... Train Accruacy: 0.734... Val Accuracy: 0.716\n",
      "Epoch: 46/50... Batch: 303/303... Train Loss: 0.173... Train Accruacy: 0.735... Val Accuracy: 0.717\n",
      "Epoch: 47/50... Batch: 303/303... Train Loss: 0.170... Train Accruacy: 0.736... Val Accuracy: 0.717\n",
      "Epoch: 48/50... Batch: 303/303... Train Loss: 0.173... Train Accruacy: 0.739... Val Accuracy: 0.718\n",
      "Epoch: 49/50... Batch: 303/303... Train Loss: 0.175... Train Accruacy: 0.740... Val Accuracy: 0.717\n",
      "Epoch: 50/50... Batch: 303/303... Train Loss: 0.175... Train Accruacy: 0.745... Val Accuracy: 0.718\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    build_and_train_network(lstm_sizes, vocab_size, embed_size, epochs, batch_size,\n",
    "                            learning_rate, keep_prob, train_x, val_x, train_y, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we want to do is check the model accuracy on our testing data to make sure it is in line with expecations. We build the Computational Graph just like we did before, however, now instead of training we restore our saved model from our checkpoint directory and then run our test data through the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_network(model_dir, batch_size, test_x, test_y):\n",
    "    \n",
    "    inputs_, labels_, keep_prob_ = model_inputs()\n",
    "    embed = build_embedding_layer(inputs_, vocab_size, embed_size)\n",
    "    initial_state, lstm_outputs, lstm_cell, final_state = build_lstm_layers(lstm_sizes, embed, keep_prob_, batch_size)\n",
    "    predictions, loss, optimizer = build_cost_fn_and_opt(lstm_outputs, labels_, learning_rate)\n",
    "    accuracy = build_accuracy(predictions, labels_)\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    test_acc = []\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, tf.train.latest_checkpoint(model_dir))\n",
    "        test_state = sess.run(lstm_cell.zero_state(batch_size, tf.float32))\n",
    "        for ii, (x, y) in enumerate(utl.get_batches(test_x, test_y, batch_size), 1):\n",
    "            feed = {inputs_: x,\n",
    "                    labels_: y[:, None],\n",
    "                    keep_prob_: 1,\n",
    "                    initial_state: test_state}\n",
    "            batch_acc, test_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "            test_acc.append(batch_acc)\n",
    "        print(\"Test Accuracy: {:.3f}\".format(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/sentiment.ckpt\n",
      "Test Accuracy: 0.717\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    test_network('checkpoints', batch_size, test_x, test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
