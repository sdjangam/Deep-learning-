# Deep-learning-


# Deep learning

Deep learning has caught a great momentum in the last few years. Research in the field of deep learning is progressing amazingly fast. Deep Learning is a rapidly growing area of machine learning. Machine learning has seen numerous successes but applying learning algorithms today often means spending a long time hand-engineering the input feature representation. This is true for many problems in vision, audio, NLP, robotics, and other areas. To address this, researchers have developed deep learning algorithms that automatically learn a good representation for the input. These algorithms are today enabling many groups to achieve ground-breaking results in vision, speech, language, robotics, and other areas.

I already discuss the basics of artificial neural networks in the machine learning module. Further, in this module, I will focus on other popular deep learning architectures like Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs) and Long Short Term Memory (LSTMs) Networks.


# CNNs

ImageNet and visual recognition problems

Biological inspiration for CNNs

Applications of CNNs

Why not just use MLPs for images?

CONV layer of a CNN

Details of CONV layer of a CNN

Stride and Pad for CONV layers of a CNN

Neuron view of the convolution layer

RELU in CNNs

Pooling and fully connected layers in CNNs

AlexNet and Hyper-parameter Optimization

Python Code: CNNs for Hand-written digit recognition using Tensorflow

Python Code: CNNs for Hand-written digit recognition using Keras

Python Code: Simple image classification with Inception Model




![image](https://user-images.githubusercontent.com/67232573/114190848-a0196280-9900-11eb-8b6d-7bdfc4ca078f.png)






# RNNs and LSTMs

Motivation for sequence learning model

Neural Language Model using MLPs

Introduction to Recurrent Neural Networks

Back-propagation for RNNs

RNN design options

CNN-RNN architecture for image captioning

Deep Bidirectional RNNs for opinion mining

Sequence Learning for machine translation using RNNs

Drawbacks of RNNs

Solutions for the exploding gradient problem

Memory based models: Gated Recurrent Units (GRUs)

Long Short-Term Memory Networks (LSTMs)

LSTM Variants

LSTM Hyperparameter tuning

Applications of RNNs and LSTMs: Video analytics, Hate Speech Detection, Extractive Summarization

Applications of RNNs and LSTMs: Translation Quality Estimation, Text Segmentation, Recommendation Systems

Applications of RNNs and LSTMs: Medical Social Media Analysis

Python Code: Classify movie reviews â€” binary classification using Keras.

Python Code: RNNs for Hand-written digit recognition using Tensorflow

Python Code: Bi-directional RNNs for Hand-written digit recognition using Tensorflow

Python Code: Next word prediction using RNNs




![image](https://user-images.githubusercontent.com/67232573/114190938-ba534080-9900-11eb-8025-c9c03919eb9c.png)






# Tensorboard

Python Code: Scalars, graphs, distributions and histograms using TensorBoard



![image](https://user-images.githubusercontent.com/67232573/114191005-cc34e380-9900-11eb-9a10-1d1d880c14c1.png)





# IoT and Sensor Data collection

What is IoT?

RFID and other sensors

IoT Applications: Smart Grid and Intelligent Transportation

IoT Applications: ANPR and Quantified Self

Arduino and Proteus

Blinking LED with Arduino+Proteus

Arduino Input Output

Using Temperature Sensors to collect temperature data





![image](https://user-images.githubusercontent.com/67232573/114191089-e4a4fe00-9900-11eb-9d48-c0b431e43564.png)

